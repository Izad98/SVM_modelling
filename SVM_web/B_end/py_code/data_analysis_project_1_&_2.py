# -*- coding: utf-8 -*-
"""Data Analysis Project 1 & 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jd8r4u6CXjEuB2sI31IA0-FuTCFy1KiI
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from scipy import stats
import seaborn as sns
import matplotlib.pyplot as plt
from pycorrcat.pycorrcat import plot_corr, corr_matrix
from sklearn.linear_model import LogisticRegression #This is for logistic regression
from sklearn.metrics import confusion_matrix, accuracy_score,classification_report,roc_curve,roc_auc_score #Metrics for classification
from imblearn.over_sampling import SMOTE,ADASYN
from sklearn.linear_model import RidgeClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier
from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,roc_curve,roc_auc_score
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis #LDA,QDA
from sklearn.naive_bayes import GaussianNB #Naive Bayes
from sklearn.datasets import make_classification
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from collections import Counter
from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
from sklearn.model_selection import KFold
import xgboost as xgb
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

import pip
pip.main(["install","xgboost"])

import pip
pip.main(["install","pycorr"])

df=pd.read_csv("../app/aug_train.CSV")

df

df_new=df.drop("enrollee_id",axis=1) # Since enrolle_id is meaningless feature, it is removed from the dataframe 
df_new

df_new.duplicated().sum() # Are there any duplicated rows?

df_new.drop_duplicates(inplace=True)
df_new

df_new.duplicated().sum()

len(df_new)

x=df_new.iloc[:,:12] #upto the 12 without 12
y=df_new.iloc[:,12]

x

y

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

x_train

"""
# Data Cleaning
"""

x_train.isna().any() # Are there any missing values in each coloumn?

y_train.isna().any()

x_train.isna().sum() # No of missing values in each coloumn



# Since the missing values are only in the categorical variables, "MODE" will be used to impute the missing values

x_train['gender'].mode()

x_train['gender'].fillna('Male',inplace=True)

x_test['gender'].fillna('Male',inplace=True)



x_train['enrolled_university'].mode()

x_train['enrolled_university'].fillna('no_enrollment',inplace=True)

x_test['enrolled_university'].fillna('no_enrollment',inplace=True)



x_train['education_level'].mode()

x_train['education_level'].fillna('Graduate',inplace=True)

x_test['education_level'].fillna('Graduate',inplace=True)



x_train['major_discipline'].mode()

x_train['major_discipline'].fillna('STEM',inplace=True)

x_test['major_discipline'].fillna('STEM',inplace=True)



x_train['experience'].mode()

x_train['experience'].fillna('>20',inplace=True)

x_test['experience'].fillna('>20',inplace=True)



x_train['company_size'].mode()

x_train['company_size'].fillna('50-99',inplace=True)

x_test['company_size'].fillna('50-99',inplace=True)



x_train['company_type'].mode()

x_train['company_type'].fillna('Pvt Ltd',inplace=True)

x_test['company_type'].fillna('Pvt Ltd',inplace=True)



x_train['last_new_job'].mode()

x_train['last_new_job'].fillna('1',inplace=True)

x_test['last_new_job'].fillna('1',inplace=True)



x_train.isna().sum()/len(df)

x_test.isna().sum()/len(df)



x_train

# Are there any outliers in continuous variables

boxplot=x_train.boxplot(column=["city_development_index","training_hours"])

x_train.boxplot(column ='city_development_index')

x_train.boxplot(column ='training_hours')

trainDataSet = pd.concat([x_train, y_train], axis=1)

trainDataSet

testDataSet = pd.concat([x_test, y_test], axis=1)

testDataSet



trainDataSet.to_csv("trainDataSet.csv")

testDataSet.to_csv("testDataSet.csv")

x_train.to_csv("x_train.csv")

y_train.to_csv("y_train.csv")

x_test.to_csv("x_test.csv")

y_test.to_csv("y_test.csv")



y_train



sns.heatmap(trainDataSet.corr(),vmin=-1,vmax=1,annot=True)
plt.show()

trainDataSet.corr()

corr_matrix(trainDataSet,['city','gender','relevent_experience','enrolled_university','education_level','major_discipline','experience','company_size','company_type','last_new_job','target'])

plot_corr(trainDataSet,['city','gender','relevent_experience','enrolled_university','education_level','major_discipline','experience','company_size','company_type','last_new_job','target'])

x_train.dtypes

x_train[["city","gender","relevent_experience","enrolled_university","education_level","major_discipline","experience","company_size","company_type","last_new_job"]] = x_train[["city","gender","relevent_experience","enrolled_university","education_level","major_discipline","experience","company_size","company_type","last_new_job"]].astype("category")

x_train.dtypes



x_test.dtypes

x_test[["city","gender","relevent_experience","enrolled_university","education_level","major_discipline","experience","company_size","company_type","last_new_job"]] = x_test[["city","gender","relevent_experience","enrolled_university","education_level","major_discipline","experience","company_size","company_type","last_new_job"]].astype("category")

x_test.dtypes



x_train_new=pd.get_dummies(x_train[['city','gender','enrolled_university','relevent_experience','education_level','experience',
                              'major_discipline','company_type','company_size','last_new_job']],drop_first=True)
x_train_new.head()

x_test_new=pd.get_dummies(x_test[['city','gender','enrolled_university','relevent_experience','education_level','experience',
                              'major_discipline','company_type','company_size','last_new_job']],drop_first=True)
x_test_new.head()

# Get missing columns in the training test
missing_cols = set( x_train_new.columns ) - set( x_test_new.columns )

missing_cols

x_test_new= x_test_new.reindex(columns = x_train_new.columns, fill_value=0)

missing_cols = set( x_train_new.columns ) - set( x_test_new.columns )
missing_cols

x_train_new.shape

x_test_new.shape



y_train

y_train.dtypes

y_train = y_train.astype("category")

y_train.dtypes



y_test

y_test.dtypes

y_test = y_test.astype("category")

y_test.dtypes

y_train.value_counts()

"""# Performing SMOTE"""

smt=SMOTE()

x_sm,y_sm=smt.fit_resample(x_train_new,y_train)

y_sm.value_counts()

"""# Over sampling (SMOTE)

## 1) Logistic
"""

# define models and parameters
model = LogisticRegression()
solvers = ['newton-cg', 'lbfgs', 'liblinear']
penalty = ['l2']
c_values = [100, 10, 1.0, 0.1, 0.01]
# define grid search
grid = dict(solver=solvers,penalty=penalty,C=c_values)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_sm,y_sm)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))



lr = LogisticRegression(C=100,penalty='l2',solver='newton-cg')
lr.fit(x_sm,y_sm)

"""## 2)Ridge"""

params = {"alpha":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}
model = RidgeClassifier()
CV = KFold(n_splits=10,shuffle=True)

gsearch = GridSearchCV(model, params,cv=CV)

results = gsearch.fit(x_sm, y_sm)

results.best_params_

rr = RidgeClassifier(alpha=0.1)
rr.fit(x_sm, y_sm)

"""## 3)Bagging"""

# define models and parameters
model = BaggingClassifier()
n_estimators = [10, 100, 1000]
# define grid search
grid = dict(n_estimators=n_estimators)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_sm,y_sm)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

bag = BaggingClassifier(n_estimators=100)
bag.fit(x_sm, y_sm)

"""## 4)Random Forest"""

# define models and parameters
model = RandomForestClassifier()
n_estimators = [10, 100]
max_features = ['sqrt', 'log2']
# define grid search
grid = dict(n_estimators=n_estimators,max_features=max_features)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_sm,y_sm)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

rf = RandomForestClassifier(max_features= 'log2', n_estimators= 100)
rf.fit(x_sm, y_sm)

"""## 5)KNN"""

# define models and parameters
model = KNeighborsClassifier()
n_neighbors = range(5)
weights = ['uniform', 'distance']
metric = ['euclidean', 'manhattan', 'minkowski']
# define grid search
grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_sm,y_sm)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

knn = KNeighborsClassifier(n_neighbors=5,weights='distance',metric='manhattan')
knn.fit(x_sm, y_sm)

"""## 6)SVM"""

model = SVC()
kernel = ['poly', 'rbf', 'sigmoid']
C = [50, 10, 1.0, 0.1, 0.01]
gamma = ['scale']
# define grid search
grid = dict(kernel=kernel,C=C,gamma=gamma)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_sm, y_sm)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

SVM = SVC(C= 50, gamma='scale', kernel= 'poly')
SVM.fit(x_sm, y_sm)

"""## 7)GradientBoosting"""

# define models and parameters
model = GradientBoostingClassifier()
n_estimators = [10, 100]
learning_rate = [0.01, 0.1]
subsample = [0.5, 1.0]
max_depth = [3, 7]
# define grid search
grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_sm, y_sm)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

gradrg=GradientBoostingClassifier(learning_rate = 0.1, max_depth = 7, n_estimators = 100, subsample = 0.5)
gradrg.fit(x_sm, y_sm)

"""## 9)LDA"""

# define models and parameters
model = LinearDiscriminantAnalysis()
solver = ['svd', 'lsqr', 'eigen']
shrinkage = ['auto','None']
# define grid search
grid = dict(solver=solver, shrinkage=shrinkage)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_sm, y_sm)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

lda=LinearDiscriminantAnalysis(shrinkage = 'auto', solver = 'lsqr')
lda.fit(x_sm, y_sm)



def get_performances(actual_Y, pred_Y):
    cm = confusion_matrix(actual_Y, pred_Y.round())
    total = sum(sum(cm))
    accuracy = (cm[0,0]+cm[1,1])/total
    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])
    specificity = cm[1,1]/(cm[1,0]+cm[1,1])
    return accuracy, sensitivity, specificity

pred_Y_lr = lr.predict(x_test_new) # predicts the Y given the fitted model Logistic Regression
pred_Y_rr = rr.predict(x_test_new) # predicts the Y given the fitted model Ridge Regression
pred_Y_bag = bag.predict(x_test_new) # predicts the Y given the fitted model Bagging
pred_Y_rf = rf.predict(x_test_new) # predicts the Y given the fitted model Random Forest
pred_Y_knn = knn.predict(x_test_new) # predicts the Y given the fitted model KNN
pred_Y_svm = SVM.predict(x_test_new) # predicts the Y given the fitted model Support Vector Machines
pred_Y_gradrg = gradrg.predict(x_test_new) # predicts the Y given the fitted model Gradient Boosting
pred_Y_lda = lda.predict(x_test_new) # predicts the Y given the fitted model LDA

# accuracy, sensitivity, and specificity for model Random Forest
accuracy_lr, sensitivity_lr, specificity_lr = get_performances(y_test, pred_Y_lr)

# accuracy, sensitivity, and specificity for model Random Forest
accuracy_rr, sensitivity_rr, specificity_rr = get_performances(y_test, pred_Y_rr)

# accuracy, sensitivity, and specificity for model Random Forest
accuracy_bag, sensitivity_bag, specificity_bag = get_performances(y_test, pred_Y_bag)

# accuracy, sensitivity, and specificity for model Random Forest
accuracy_rf, sensitivity_rf, specificity_rf = get_performances(y_test, pred_Y_rf)

# accuracy, sensitivity, and specificity for model KNN
accuracy_knn, sensitivity_knn, specificity_knn = get_performances(y_test, pred_Y_knn)

# accuracy, sensitivity, and specificity for model Support Vector Machines
accuracy_svm, sensitivity_svm, specificity_svm = get_performances(y_test, pred_Y_svm)

# accuracy, sensitivity, and specificity for model Gradient Boosting
accuracy_gradrg, sensitivity_gradrg, specificity_gradrg = get_performances(y_test, pred_Y_gradrg)

# accuracy, sensitivity, and specificity for model LDA
accuracy_lda, sensitivity_lda, specificity_lda = get_performances(y_test, pred_Y_lda)

perf = pd.DataFrame([accuracy_lr,accuracy_rr,accuracy_bag,accuracy_rf,accuracy_knn,accuracy_svm,accuracy_gradrg,accuracy_lda], 
                    columns = ['Accuracy'], 
                    index = ['Logistic Regression','Ridge Regression','Bagging','Random Forest','KNN','Support Vector Machine','Gradient Boosting','LDA'])

perf['Sensitivity'] = np.asarray([sensitivity_lr,sensitivity_rr,sensitivity_bag,sensitivity_rf,
                                  sensitivity_knn,sensitivity_svm,sensitivity_gradrg,sensitivity_lda])

perf['Specificity'] = np.asarray([specificity_lr,specificity_rr,specificity_bag,specificity_rf,
                                  specificity_knn,specificity_svm,specificity_gradrg,specificity_lda])
perf

"""# Without re-sampling (SMOTE)

## 1) Logistic
"""

lr = LogisticRegression(C=100,penalty='l2',solver='newton-cg')
lr.fit(x_train_new,y_train)

"""## 2) Ridge"""

rr = RidgeClassifier(alpha=0.7)
rr.fit(x_train_new,y_train)

"""## 3)Bagging"""

bag = BaggingClassifier()
bag.fit(x_train_new,y_train)

"""## 4)Rndom Forest"""

rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)
rf.fit(x_train_new,y_train)

"""## 5)KNN"""

knn = KNeighborsClassifier(n_neighbors = 5)
knn.fit(x_train_new,y_train)

"""## 6)SVM"""

SVM = svm.LinearSVC()
SVM.fit(x_train_new,y_train)

"""## 7)Gradient Boosting"""

gradrg=GradientBoostingClassifier()
gradrg.fit(x_train_new,y_train)

"""## 8)LDA"""

lda=LinearDiscriminantAnalysis()
lda.fit(x_train_new,y_train)



def get_performances(actual_Y, pred_Y):
    cm = confusion_matrix(actual_Y, pred_Y.round())
    total = sum(sum(cm))
    accuracy = (cm[0,0]+cm[1,1])/total
    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])
    specificity = cm[1,1]/(cm[1,0]+cm[1,1])
    return accuracy, sensitivity, specificity

pred_Y_lr = lr.predict(x_test_new) # predicts the Y given the fitted model Logistic Regression
pred_Y_rr = rr.predict(x_test_new) # predicts the Y given the fitted model Ridge Regression
pred_Y_bag = bag.predict(x_test_new) # predicts the Y given the fitted model Bagging
pred_Y_rf = rf.predict(x_test_new) # predicts the Y given the fitted model Random Forest
pred_Y_knn = knn.predict(x_test_new) # predicts the Y given the fitted model KNN
pred_Y_svm = SVM.predict(x_test_new) # predicts the Y given the fitted model Support Vector Machines
pred_Y_gradrg = gradrg.predict(x_test_new) # predicts the Y given the fitted model Gradient Boosting
pred_Y_lda = lda.predict(x_test_new) # predicts the Y given the fitted model LDA

# accuracy, sensitivity, and specificity for model Logistic Regression
accuracy_lr, sensitivity_lr, specificity_lr = get_performances(y_test, pred_Y_lr)

# accuracy, sensitivity, and specificity for model Random Ridge Regression
accuracy_rr, sensitivity_rr, specificity_rr = get_performances(y_test, pred_Y_rr)

# accuracy, sensitivity, and specificity for model Random Bagging
accuracy_bag, sensitivity_bag, specificity_bag = get_performances(y_test, pred_Y_bag)

# accuracy, sensitivity, and specificity for model Random Forest
accuracy_rf, sensitivity_rf, specificity_rf = get_performances(y_test, pred_Y_rf)

# accuracy, sensitivity, and specificity for model KNN
accuracy_knn, sensitivity_knn, specificity_knn = get_performances(y_test, pred_Y_knn)

# accuracy, sensitivity, and specificity for model Support Vector Machines
accuracy_svm, sensitivity_svm, specificity_svm = get_performances(y_test, pred_Y_svm)

# accuracy, sensitivity, and specificity for model Gradient Boosting
accuracy_gradrg, sensitivity_gradrg, specificity_gradrg = get_performances(y_test, pred_Y_gradrg)

# accuracy, sensitivity, and specificity for model LDA
accuracy_lda, sensitivity_lda, specificity_lda = get_performances(y_test, pred_Y_lda)

perf = pd.DataFrame([accuracy_lr,accuracy_rr,accuracy_bag,accuracy_rf,accuracy_knn,accuracy_svm,accuracy_gradrg,accuracy_lda], 
                    columns = ['Accuracy'], 
                    index = ['Logistic Regression','Ridge Regression','Bagging','Random Forest','KNN','Support Vector Machine','Gradient Boosting','LDA'])

perf['Sensitivity'] = np.asarray([sensitivity_lr,sensitivity_rr,sensitivity_bag,sensitivity_rf,
                                  sensitivity_knn,sensitivity_svm,sensitivity_gradrg,sensitivity_lda])

perf['Specificity'] = np.asarray([specificity_lr,specificity_rr,specificity_bag,specificity_rf,
                                  specificity_knn,specificity_svm,specificity_gradrg,specificity_lda])
perf

"""# -----------------------------------------------------------------------------------------------------------

# Random Under Sampling
"""

# instantiating the random undersampler
rus = RandomUnderSampler() 
# resampling X, y
x_rus, y_rus = rus.fit_resample(x_train_new,y_train)

"""## 1)Logistic"""

# define models and parameters
model = LogisticRegression()
solvers = ['newton-cg', 'lbfgs', 'liblinear']
penalty = ['l2']
c_values = [100, 10, 1.0, 0.1, 0.01]
# define grid search
grid = dict(solver=solvers,penalty=penalty,C=c_values)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_rus, y_rus)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

lr = LogisticRegression(C=10,penalty='l2',solver='newton-cg',random_state=1)
lr.fit(x_rus,y_rus)

"""## 2)Ridge"""

params = {"alpha":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}
model = RidgeClassifier()
CV = KFold(n_splits=10,shuffle=True)

gsearch = GridSearchCV(model, params,cv=CV)

results = gsearch.fit(x_rus,y_rus)

results.best_params_

rr = RidgeClassifier(alpha=0.6,random_state=1)
rr.fit(x_rus, y_rus)

"""## 3)Bagging"""

# define models and parameters
model = BaggingClassifier()
n_estimators = [10, 100, 1000]
# define grid search
grid = dict(n_estimators=n_estimators)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_rus,y_rus)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

bag = BaggingClassifier(n_estimators = 100,random_state=1)
bag.fit(x_rus, y_rus)

"""## 4)Random Forest"""

# define models and parameters
model = RandomForestClassifier()
n_estimators = [10, 100]
max_features = ['sqrt', 'log2']
# define grid search
grid = dict(n_estimators=n_estimators,max_features=max_features)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_rus, y_rus)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

rf = RandomForestClassifier(n_estimators=100, max_depth=5, max_features = 'log2',random_state=1)
rf.fit(x_rus, y_rus)

pred_Y_rf = rf.predict(x_test_new)

from sklearn.metrics import roc_curve
from sklearn.metrics import auc
fpr, tpr, thresholds = roc_curve(y_test, pred_Y_rf)
a=auc(fpr,tpr)
print("Area under the curve:",a)

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % a)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()

confusion_matrixrf = confusion_matrix(y_test, pred_Y_rf)
print(confusion_matrixrf)

"""## 5)KNN"""

# define models and parameters
model = KNeighborsClassifier()
n_neighbors = range(5)
weights = ['uniform', 'distance']
metric = ['euclidean', 'manhattan', 'minkowski']
# define grid search
grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_rus, y_rus)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

knn = KNeighborsClassifier(metric = 'euclidean', n_neighbors = 4, weights = 'uniform')
knn.fit(x_rus, y_rus)

pred_Y_knn = knn.predict(x_test_new)

fpr, tpr, thresholds = roc_curve(y_test, pred_Y_knn)
a=auc(fpr,tpr)
print("Area under the curve:",a)

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % a)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()

confusion_matrixknn = confusion_matrix(y_test, pred_Y_knn)
print(confusion_matrixknn)

"""## 6)SVM"""

model = SVC()
kernel = ['poly', 'rbf', 'sigmoid']
C = [50, 10, 1.0]
gamma = ['scale']
# define grid search
grid = dict(kernel=kernel,C=C,gamma=gamma)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_rus, y_rus)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

SVM = SVC(C= 1.0, gamma='scale', kernel= 'rbf',random_state=1)
SVM.fit(x_rus, y_rus)

import joblib

filename = "C:\\Users\\User\\Desktop\\Data Analysis 1\\finalized_model.sav"

joblib.dump(SVM, filename)

"""## 7)GradientBoosting"""

# define models and parameters
model = GradientBoostingClassifier()
n_estimators = [10, 100]
learning_rate = [0.01, 0.1]
subsample = [0.5, 1.0]
max_depth = [3, 7]
# define grid search
grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_rus, y_rus)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

gradrg=GradientBoostingClassifier(learning_rate = 0.1, max_depth = 3, n_estimators = 100, subsample = 0.5,random_state=1)
gradrg.fit(x_rus, y_rus)

"""## 8)LDA"""

# define models and parameters
model = LinearDiscriminantAnalysis()
solver = ['svd', 'lsqr', 'eigen']
shrinkage = ['auto','None']
# define grid search
grid = dict(solver=solver, shrinkage=shrinkage)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_rus, y_rus)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

lda=LinearDiscriminantAnalysis(shrinkage = 'auto', solver = 'lsqr')
lda.fit(x_rus,y_rus)



def get_performances(actual_Y, pred_Y):
    cm = confusion_matrix(actual_Y, pred_Y.round())
    total = sum(sum(cm))
    accuracy = (cm[0,0]+cm[1,1])/total
    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])
    specificity = cm[1,1]/(cm[1,0]+cm[1,1])
    return accuracy, sensitivity, specificity

pred_Y_lr = lr.predict(x_test_new) # predicts the Y given the fitted model Logistic Regression
pred_Y_rr = rr.predict(x_test_new) # predicts the Y given the fitted model Ridge Regression
pred_Y_bag = bag.predict(x_test_new) # predicts the Y given the fitted model Bagging
pred_Y_rf = rf.predict(x_test_new) # predicts the Y given the fitted model Random Forest
pred_Y_knn = knn.predict(x_test_new) # predicts the Y given the fitted model KNN
pred_Y_svm = SVM.predict(x_test_new) # predicts the Y given the fitted model Support Vector Machines
pred_Y_gradrg = gradrg.predict(x_test_new) # predicts the Y given the fitted model Gradient Boosting
pred_Y_lda = lda.predict(x_test_new) # predicts the Y given the fitted model LDA

# accuracy, sensitivity, and specificity for model Logistic Regression
accuracy_lr, sensitivity_lr, specificity_lr = get_performances(y_test, pred_Y_lr)

# accuracy, sensitivity, and specificity for model Random Ridge Regression
accuracy_rr, sensitivity_rr, specificity_rr = get_performances(y_test, pred_Y_rr)

# accuracy, sensitivity, and specificity for model Random Bagging
accuracy_bag, sensitivity_bag, specificity_bag = get_performances(y_test, pred_Y_bag)

# accuracy, sensitivity, and specificity for model Random Forest
accuracy_rf, sensitivity_rf, specificity_rf = get_performances(y_test, pred_Y_rf)

# accuracy, sensitivity, and specificity for model KNN
accuracy_knn, sensitivity_knn, specificity_knn = get_performances(y_test, pred_Y_knn)

# accuracy, sensitivity, and specificity for model Support Vector Machines
accuracy_svm, sensitivity_svm, specificity_svm = get_performances(y_test, pred_Y_svm)

# accuracy, sensitivity, and specificity for model Gradient Boosting
accuracy_gradrg, sensitivity_gradrg, specificity_gradrg = get_performances(y_test, pred_Y_gradrg)

# accuracy, sensitivity, and specificity for model LDA
accuracy_lda, sensitivity_lda, specificity_lda = get_performances(y_test, pred_Y_lda)

perf = pd.DataFrame([accuracy_lr,accuracy_rr,accuracy_bag,accuracy_rf,accuracy_knn,accuracy_svm,accuracy_gradrg,accuracy_lda], 
                    columns = ['Accuracy'], 
                    index = ['Logistic Regression','Ridge Regression','Bagging','Random Forest','KNN','Support Vector Machine','Gradient Boosting','LDA'])

perf['Sensitivity'] = np.asarray([sensitivity_lr,sensitivity_rr,sensitivity_bag,sensitivity_rf,
                                  sensitivity_knn,sensitivity_svm,sensitivity_gradrg,sensitivity_lda])

perf['Specificity'] = np.asarray([specificity_lr,specificity_rr,specificity_bag,specificity_rf,
                                  specificity_knn,specificity_svm,specificity_gradrg,specificity_lda])
perf

"""# -----------------------------------------------------------------------------------------------------------

# SMOTE + Under sampling
"""

from imblearn.pipeline import Pipeline
# define pipeline
over = SMOTE(sampling_strategy=0.6, random_state=42)
under = RandomUnderSampler(sampling_strategy=0.9, random_state=42)
steps = [('o', over), ('u', under)]
pipeline = Pipeline(steps=steps)
# transform the dataset
x_smun, y_smun = pipeline.fit_resample(x_train_new,y_train)

"""## 1)Logistic"""

# define models and parameters
model = LogisticRegression()
solvers = ['newton-cg', 'lbfgs', 'liblinear']
penalty = ['l2']
c_values = [100, 10, 1.0, 0.1, 0.01]
# define grid search
grid = dict(solver=solvers,penalty=penalty,C=c_values)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_smun, y_smun)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

lr = LogisticRegression(C=10,penalty='l2',solver='liblinear')
lr.fit(x_smun, y_smun)

"""## 2)Ridge"""

params = {"alpha":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}
model = RidgeClassifier()
CV = KFold(n_splits=10,shuffle=True)

gsearch = GridSearchCV(model, params,cv=CV)

results = gsearch.fit(x_smun, y_smun)

results.best_params_

rr = RidgeClassifier(alpha=0.1)
rr.fit(x_smun, y_smun)

"""## 3)Bagging"""

# define models and parameters
model = BaggingClassifier()
n_estimators = [10, 100, 1000]
# define grid search
grid = dict(n_estimators=n_estimators)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_smun, y_smun)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

bag = BaggingClassifier(n_estimators = 100)
bag.fit(x_smun, y_smun)

"""## 4)Random Forest"""

# define models and parameters
model = RandomForestClassifier()
n_estimators = [10, 100]
max_features = ['sqrt', 'log2']
# define grid search
grid = dict(n_estimators=n_estimators,max_features=max_features)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_smun, y_smun)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

rf = RandomForestClassifier(n_estimators=100, max_depth=5, max_features = 'log2')
rf.fit(x_smun, y_smun)

"""## 5)KNN"""

# define models and parameters
model = KNeighborsClassifier()
n_neighbors = range(5)
weights = ['uniform', 'distance']
metric = ['euclidean', 'manhattan', 'minkowski']
# define grid search
grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_smun, y_smun)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

knn = KNeighborsClassifier(metric = 'euclidean', n_neighbors = 4, weights = 'uniform')
knn.fit(x_smun, y_smun)

"""## 6)SVM"""

model = SVC()
kernel = ['poly', 'rbf', 'sigmoid']
C = [50, 10, 1.0]
gamma = ['scale']
# define grid search
grid = dict(kernel=kernel,C=C,gamma=gamma)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_smun, y_smun)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

SVM = SVC(C= 1.0, gamma='scale', kernel= 'rbf')
SVM.fit(x_smun, y_smun)

"""## 7)Gradient Boosting"""

# define models and parameters
model = GradientBoostingClassifier()
n_estimators = [10, 100]
learning_rate = [0.01, 0.1]
subsample = [0.5, 1.0]
max_depth = [3, 7]
# define grid search
grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_smun, y_smun)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

gradrg=GradientBoostingClassifier(learning_rate = 0.1, max_depth = 7, n_estimators = 100, subsample = 0.5)
gradrg.fit(x_smun, y_smun)

"""## 8)LDA"""

# define models and parameters
model = LinearDiscriminantAnalysis()
solver = ['svd', 'lsqr', 'eigen']
shrinkage = ['auto','None']
# define grid search
grid = dict(solver=solver, shrinkage=shrinkage)
CV = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=CV, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(x_smun, y_smun)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

lda=LinearDiscriminantAnalysis(shrinkage = 'auto', solver = 'lsqr')
lda.fit(x_smun, y_smun)

def get_performances(actual_Y, pred_Y):
    cm = confusion_matrix(actual_Y, pred_Y.round())
    total = sum(sum(cm))
    accuracy = (cm[0,0]+cm[1,1])/total
    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])
    specificity = cm[1,1]/(cm[1,0]+cm[1,1])
    return accuracy, sensitivity, specificity

pred_Y_lr = lr.predict(x_test_new) # predicts the Y given the fitted model Logistic Regression
pred_Y_rr = rr.predict(x_test_new) # predicts the Y given the fitted model Ridge Regression
pred_Y_bag = bag.predict(x_test_new) # predicts the Y given the fitted model Bagging
pred_Y_rf = rf.predict(x_test_new) # predicts the Y given the fitted model Random Forest
pred_Y_knn = knn.predict(x_test_new) # predicts the Y given the fitted model KNN
pred_Y_svm = SVM.predict(x_test_new) # predicts the Y given the fitted model Support Vector Machines
pred_Y_gradrg = gradrg.predict(x_test_new) # predicts the Y given the fitted model Gradient Boosting
pred_Y_lda = lda.predict(x_test_new) # predicts the Y given the fitted model LDA

# accuracy, sensitivity, and specificity for model Logistic Regression
accuracy_lr, sensitivity_lr, specificity_lr = get_performances(y_test, pred_Y_lr)

# accuracy, sensitivity, and specificity for model Random Ridge Regression
accuracy_rr, sensitivity_rr, specificity_rr = get_performances(y_test, pred_Y_rr)

# accuracy, sensitivity, and specificity for model Random Bagging
accuracy_bag, sensitivity_bag, specificity_bag = get_performances(y_test, pred_Y_bag)

# accuracy, sensitivity, and specificity for model Random Forest
accuracy_rf, sensitivity_rf, specificity_rf = get_performances(y_test, pred_Y_rf)

# accuracy, sensitivity, and specificity for model KNN
accuracy_knn, sensitivity_knn, specificity_knn = get_performances(y_test, pred_Y_knn)

# accuracy, sensitivity, and specificity for model Support Vector Machines
accuracy_svm, sensitivity_svm, specificity_svm = get_performances(y_test, pred_Y_svm)

# accuracy, sensitivity, and specificity for model Gradient Boosting
accuracy_gradrg, sensitivity_gradrg, specificity_gradrg = get_performances(y_test, pred_Y_gradrg)

# accuracy, sensitivity, and specificity for model LDA
accuracy_lda, sensitivity_lda, specificity_lda = get_performances(y_test, pred_Y_lda)

perf = pd.DataFrame([accuracy_lr,accuracy_rr,accuracy_bag,accuracy_rf,accuracy_knn,accuracy_svm,accuracy_gradrg,accuracy_lda], 
                    columns = ['Accuracy'], 
                    index = ['Logistic Regression','Ridge Regression','Bagging','Random Forest','KNN','Support Vector Machine','Gradient Boosting','LDA'])

perf['Sensitivity'] = np.asarray([sensitivity_lr,sensitivity_rr,sensitivity_bag,sensitivity_rf,
                                  sensitivity_knn,sensitivity_svm,sensitivity_gradrg,sensitivity_lda])

perf['Specificity'] = np.asarray([specificity_lr,specificity_rr,specificity_bag,specificity_rf,
                                  specificity_knn,specificity_svm,specificity_gradrg,specificity_lda])
perf
